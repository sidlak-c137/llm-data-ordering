{
    "repo_path": "/gscratch/ml4ml/sidlak/cse517-final-project",
    "model_name": "TinyLlama/TinyLlama-1.1B-intermediate-step-1431k-3T",
    "experiment_name": "snli_triangle_ngram_perplexity",
    "hardness_calc": "ngram_perplexity",
    "loss_calc": "triangle",
    "data_order": null,
    "architecture_args": {
        "unfrozen_layers": ["score"],
        "quantized": null
    },
    "dataset": "snli",
    "dataset_coordinates": "data/snli_data_map_coordinates.pickle",
    "dataset_ngram_path": "data/interpolated_ngram_perplexity.jsonl",
    "num_train_samples": 50000,
    "num_val_samples": 5000,
    "num_test_samples": 5000,
    "trainer_args": {
        "optim": "adamw_torch",
        "adam_beta1": 0.9,
        "adam_beta2": 0.95,
        "weight_decay": 0.01,
        "learning_rate": 4e-4,
        "lr_scheduler_type": "constant",
        "num_warmup_steps": 0,
        "num_train_epochs": 2,
        "batch_size": 8,
        "dataloader_num_workers": 8,
        "load_best_model_at_end": true,
        "strategy": "epoch",
        "output_dir": "scripts/experiment_data/",
        "eval_every": 200
    },
    "do_train": true
}